[
  {
    "question": "인공지능의 주요 역할로 올바른 것은?",
    "options": [
      "모든 직업을 완전히 대체한다",
      "창의적인 문제 해결을 스스로 한다",
      "사람의 작업을 보조하여 효율을 높인다",
      "의사결정을 인간 대신 내려준다"
    ],
    "answer": 2,
    "explanation": "AI는 직업을 대체하기보다는 반복적인 작업을 보조하여 생산성을 높이는 역할을 한다."
  },
  {
    "question": "다음 중 인공지능의 예시로 적절하지 않은 것은?",
    "options": [
      "코드 자동 완성",
      "이미지 분류",
      "인터넷 브라우저",
      "음성 인식"
    ],
    "answer": 2,
    "explanation": "인터넷 브라우저는 인공지능 기술이 아닌 일반 소프트웨어이다."
  },
  {
    "question": "과업(Task)과 직업(Job)의 관계에 대한 설명으로 적절한 것은?",
    "options": [
      "과업은 직업보다 크다",
      "AI는 직업 전체를 대체할 수 있다",
      "AI는 과업 단위의 업무 생산성을 향상시킨다",
      "직업은 과업의 일부다"
    ],
    "answer": 2,
    "explanation": "AI는 직업 전체가 아닌, 직업을 구성하는 과업 단위에서 생산성을 높인다."
  },
  {
    "question": "다음 중 직업(Job) 예시에 해당하지 않는 것은?",
    "options": [
      "디자이너",
      "요구사항 분석",
      "간호사",
      "개발자"
    ],
    "answer": 1,
    "explanation": "요구사항 분석은 직업이 아니라 과업(Task)이다."
  },
  {
    "question": "다음 중 인공지능, 머신러닝, 딥러닝의 관계를 가장 잘 설명한 것은?",
    "options": [
      "머신러닝 ⊃ 인공지능 ⊃ 딥러닝",
      "인공지능 ⊂ 딥러닝 ⊂ 머신러닝",
      "인공지능 ⊃ 머신러닝 ⊃ 딥러닝",
      "딥러닝 ⊃ 머신러닝 ⊃ 인공지능"
    ],
    "answer": 2,
    "explanation": "딥러닝은 머신러닝의 하위 개념이고, 머신러닝은 인공지능의 하위 개념이다."
  },
  {
    "question": "딥러닝에 해당하는 기술로 올바른 것은?",
    "options": [
      "결정트리",
      "SVM",
      "트랜스포머",
      "k-NN"
    ],
    "answer": 2,
    "explanation": "트랜스포머는 딥러닝 기반의 모델이다. 나머지는 머신러닝에 해당한다."
  },
  {
    "question": "머신러닝의 핵심 구성요소는 무엇인가?",
    "options": [
      "정책, 행동",
      "데이터, 모델",
      "모델, 시뮬레이터",
      "알고리즘, 논리"
    ],
    "answer": 1,
    "explanation": "머신러닝은 데이터를 기반으로 모델을 학습시켜 예측하는 구조이다."
  },
  {
    "question": "머신러닝에서 학습(training)이란 무엇인가?",
    "options": [
      "알고리즘을 코딩하는 것",
      "사용자의 피드백을 받는 것",
      "데이터로부터 패턴을 찾는 것",
      "하드웨어를 설정하는 것"
    ],
    "answer": 2,
    "explanation": "학습이란 데이터를 통해 규칙과 패턴을 모델이 자동으로 습득하는 것이다."
  },
  {
    "question": "딥러닝을 위한 기본 구성 요소가 아닌 것은?",
    "options": [
      "컴퓨팅 자원",
      "프로그램",
      "정답이 없는 데이터",
      "데이터"
    ],
    "answer": 2,
    "explanation": "딥러닝은 주로 지도학습을 기반으로 하며 정답(라벨)이 있는 데이터가 필요하다."
  },
  {
    "question": "딥러닝 구현에 가장 적합한 환경은?",
    "options": [
      "저사양 CPU 기반 환경",
      "일반 노트북",
      "GPU 또는 TPU 환경",
      "안드로이드 스마트폰"
    ],
    "answer": 2,
    "explanation": "딥러닝은 연산량이 많아 고성능 GPU 또는 TPU 환경이 유리하다."
  },
  {
    "question": "지도학습(Supervised Learning)의 특징은?",
    "options": [
      "데이터에 라벨이 없다",
      "모델이 자체적으로 정답을 생성한다",
      "정답(라벨)이 있는 데이터를 사용한다",
      "이미 훈련된 모델만 사용한다"
    ],
    "answer": 2,
    "explanation": "지도학습은 입력 데이터에 정답(라벨)이 있어, 모델이 그 정답을 예측하도록 학습한다."
  },
  {
    "question": "비지도학습(Unsupervised Learning)의 예로 적절한 것은?",
    "options": [
      "스팸메일 분류",
      "이미지 분류",
      "군집 분석(Clustering)",
      "정답 있는 뉴스 감성 분석"
    ],
    "answer": 2,
    "explanation": "비지도학습은 라벨이 없는 데이터로 군집화, 차원 축소 등을 수행한다."
  },
  {
    "question": "다음 중 RandomForestClassifier를 사용하기 위해 필요한 라이브러리는?",
    "options": [
      "tensorflow.keras",
      "sklearn.ensemble",
      "matplotlib.pyplot",
      "pandas.core"
    ],
    "answer": 1,
    "explanation": "랜덤포레스트는 scikit-learn의 ensemble 모듈에 포함되어 있다."
  },
  {
    "question": "SVM(Support Vector Machine) 분류기를 사용하려면 어떤 클래스를 써야 할까?",
    "options": [
      "SVC",
      "KNNClassifier",
      "GradientBoostingRegressor",
      "DecisionTreePlot"
    ],
    "answer": 0,
    "explanation": "SVC는 Support Vector Classifier의 약자로 SVM을 구현하는 데 사용된다."
  },
  {
    "question": "퍼셉트론은 무엇을 모델링한 것인가?",
    "options": [
      "사람의 폐",
      "로지스틱 회귀 그래프",
      "생물학적 뉴런",
      "카메라 이미지 처리"
    ],
    "answer": 2,
    "explanation": "퍼셉트론은 생물학적 뉴런의 작동 방식을 수학적으로 모델링한 것이다."
  },
  {
    "question": "퍼셉트론의 입력에 대한 출력 결정 기준은?",
    "options": [
      "무작위 선택",
      "기울기",
      "미분 계수",
      "가중치와 임계값 비교"
    ],
    "answer": 3,
    "explanation": "퍼셉트론은 입력값에 가중치를 곱한 후, 임계값을 넘는지 여부에 따라 출력을 결정한다."
  },
  {
    "question": "구글 코랩(Google Colab)을 사용할 때 장점으로 옳은 것은?",
    "options": [
      "로컬 설치가 필요하다",
      "GPU 사용이 제한된다",
      "인터넷 없이 실행된다",
      "브라우저만 있으면 무료로 사용 가능하다"
    ],
    "answer": 3,
    "explanation": "Google Colab은 설치 없이 브라우저만으로 사용 가능하며, 무료 GPU도 제공한다."
  },
  {
    "question": "다음 중 구글 코랩에서 사용할 수 없는 기능은?",
    "options": [
      "GPU 가속",
      "텍스트 마크다운 작성",
      "구글 드라이브 연동",
      "로컬 시스템 설정 변경"
    ],
    "answer": 3,
    "explanation": "구글 코랩은 클라우드 기반이기 때문에 로컬 시스템 설정을 변경할 수 없다."
  },
  {
    "question": "다음 중 판다스(Pandas)의 기능으로 옳은 것은?",
    "options": [
      "이미지 전처리",
      "모델 학습",
      "데이터 조작 및 분석",
      "웹 페이지 크롤링"
    ],
    "answer": 2,
    "explanation": "판다스는 주로 데이터프레임 생성, 정렬, 필터링, 통계 계산 등 데이터 분석에 사용된다."
  },
  {
    "question": "판다스를 활용하여 행/열 추출을 위해 주로 사용하는 함수는?",
    "options": [
      "fetch()",
      "iloc[]",
      "view()",
      "pick[]"
    ],
    "answer": 1,
    "explanation": "`iloc[]`은 판다스에서 위치 인덱스를 기준으로 행이나 열을 추출할 때 사용된다."
  },
  {
  "question": "다음 중 선형 회귀(Linear Regression) 모델에 대한 설명으로 옳은 것은?",
  "options": [
    "출력값은 반드시 0 또는 1이다.",
    "가설 함수는 H(x) = wx + b 형태를 가진다.",
    "은닉층이 포함된 인공 신경망이다.",
    "크로스 엔트로피 손실 함수를 사용한다."
  ],
  "answer": 1,
  "explanation": "선형 회귀는 H(x) = wx + b 형태의 가설 함수를 사용하여 연속적인 값을 예측한다."
},
{
  "question": "다중 선형 회귀(Multiple Linear Regression)에서 독립 변수의 수가 늘어나면 어떻게 되는가?",
  "options": [
    "모델의 복잡도는 줄어든다.",
    "출력은 확률로 바뀐다.",
    "평면 형태의 예측 모델이 된다.",
    "모델은 항상 완벽한 예측을 보장한다."
  ],
  "answer": 2,
  "explanation": "독립 변수가 여러 개일 경우 예측 모델은 직선이 아닌 평면 형태가 된다."
},
{
  "question": "최소제곱법의 목적은 무엇인가?",
  "options": [
    "모든 데이터를 분류하는 것",
    "평균값을 예측하는 것",
    "오차의 제곱 합을 최소화하는 것",
    "모델 복잡도를 줄이는 것"
  ],
  "answer": 2,
  "explanation": "최소제곱법은 예측값과 실제값의 차이의 제곱 합을 최소화하는 것을 목표로 한다."
},
{
  "question": "최소제곱법으로 구하는 두 가지 주요 요소는?",
  "options": [
    "경사도와 에포크",
    "입력값과 출력값",
    "기울기와 y절편",
    "표준편차와 평균"
  ],
  "answer": 2,
  "explanation": "기울기 a와 y절편 b는 최소제곱법을 통해 구해지는 회귀선의 두 주요 요소이다."
},
{
  "question": "평균 제곱 오차(MSE)에 대한 설명으로 올바른 것은?",
  "options": [
    "예측값과 실제값의 합을 평균내는 함수이다.",
    "분류 모델에서 사용되는 손실 함수이다.",
    "오차의 제곱 값을 평균낸다.",
    "로지스틱 회귀에서 사용된다."
  ],
  "answer": 2,
  "explanation": "MSE는 각 예측값과 실제값의 차이를 제곱한 뒤 평균을 낸 값으로, 회귀 문제에서 자주 사용된다."
},
{
  "question": "다음 중 '일단 그리고 조금씩 수정하기' 방식에 해당하는 학습 방법은?",
  "options": [
    "선형 보간법",
    "평균 제곱 오차",
    "경사 하강법",
    "결정 트리"
  ],
  "answer": 2,
  "explanation": "경사 하강법은 초기 임의의 값을 설정한 후 오차를 줄이도록 반복 수정하는 방식이다."
},
{
  "question": "경사 하강법의 핵심 아이디어는 무엇인가?",
  "options": [
    "데이터를 정렬하는 것",
    "모든 변수의 평균값을 사용하는 것",
    "기울기를 따라 오차가 줄어드는 방향으로 이동",
    "모든 조합을 무작위로 실험"
  ],
  "answer": 2,
  "explanation": "경사 하강법은 오차 함수의 기울기를 따라 이동하면서 최소값을 찾는 알고리즘이다."
},
{
  "question": "학습률(learning rate)이 너무 큰 경우 발생할 수 있는 문제는?",
  "options": [
    "수렴 속도가 느려진다",
    "학습이 빠르고 안정적이다",
    "최솟값을 지나쳐 발산할 수 있다",
    "과적합이 무조건 발생한다"
  ],
  "answer": 2,
  "explanation": "학습률이 너무 크면 최소값을 지나쳐 오히려 오차가 커지고 발산하는 문제가 발생할 수 있다."
},
{
  "question": "머신러닝에서 '가설 함수'란 무엇을 의미하는가?",
  "options": [
    "모델을 위한 전처리 함수",
    "학습을 위한 데이터 추출 도구",
    "예측을 위한 수학적 식",
    "결과 시각화를 위한 함수"
  ],
  "answer": 2,
  "explanation": "가설 함수는 입력값을 통해 출력값을 예측하기 위한 수학적 모델을 의미한다."
},
{
  "question": "다음 중 '편향(bias)'의 역할은?",
  "options": [
    "과적합을 방지한다",
    "모델의 훈련 속도를 조절한다",
    "모든 입력에 공통으로 더해지는 값",
    "출력층의 노드 수를 결정한다"
  ],
  "answer": 2,
  "explanation": "편향은 입력에 관계없이 모든 출력에 공통적으로 더해지는 값으로, 모델의 유연성을 높여준다."
},{
  "question": "손실 함수(Loss Function)의 주된 목적은 무엇인가?",
  "options": [
    "모델을 시각화하는 도구이다",
    "오차의 정도를 수치로 나타낸다",
    "입력 데이터의 평균을 구한다",
    "출력층의 노드 수를 조절한다"
  ],
  "answer": 1,
  "explanation": "손실 함수는 실제 값과 예측 값 간의 오차를 수치화하여 모델 학습에 활용된다."
},
{
  "question": "다음 중 평균 제곱 오차(MSE)를 사용하는 경우는?",
  "options": [
    "이진 분류",
    "다항 분류",
    "회귀 문제",
    "군집 분석"
  ],
  "answer": 2,
  "explanation": "MSE는 연속적인 값을 예측하는 회귀 문제에서 손실 함수로 사용된다."
},
{
  "question": "크로스 엔트로피 손실 함수는 어떤 경우에 주로 사용되는가?",
  "options": [
    "선형 회귀 문제",
    "이진 또는 다중 분류 문제",
    "클러스터링 문제",
    "차원 축소 문제"
  ],
  "answer": 1,
  "explanation": "크로스 엔트로피는 분류 문제에서 정답 확률과 예측 확률의 차이를 측정하는 데 사용된다."
},
{
  "question": "다음 중 로지스틱 회귀에서 손실 함수로 사용하는 것은?",
  "options": [
    "평균 제곱 오차",
    "로지스틱 오차 함수",
    "크로스 엔트로피",
    "시그모이드 오차"
  ],
  "answer": 2,
  "explanation": "로지스틱 회귀에서는 크로스 엔트로피 손실 함수를 사용해 분류 오류를 최소화한다."
},
{
  "question": "다층 퍼셉트론(MLP)의 가장 큰 특징은?",
  "options": [
    "출력층만 존재한다",
    "은닉층을 포함해 입력과 출력을 연결한다",
    "정답이 필요 없다",
    "단순 선형 회귀를 구현한다"
  ],
  "answer": 1,
  "explanation": "MLP는 입력층과 출력층 사이에 하나 이상의 은닉층을 포함하는 신경망 구조이다."
},
{
  "question": "오차 역전파(backpropagation)의 핵심 개념은?",
  "options": [
    "출력층부터 입력층으로 가중치를 수정하는 것",
    "데이터를 뒤로 보내는 과정",
    "은닉층 없이 모델을 단순화하는 것",
    "가중치를 무작위로 초기화하는 것"
  ],
  "answer": 0,
  "explanation": "오차 역전파는 출력층에서 계산된 오차를 역으로 전파하여 각 층의 가중치를 수정하는 학습 방법이다."
},
{
  "question": "ReLU 함수의 동작 방식으로 옳은 것은?",
  "options": [
    "모든 입력에 대해 로그를 취한다",
    "0 이하 값은 0으로, 0 초과 값은 그대로 출력",
    "입력을 모두 제곱한다",
    "입력을 0과 1 사이로 압축한다"
  ],
  "answer": 1,
  "explanation": "ReLU(Rectified Linear Unit)는 0 이하 입력은 0으로, 양수는 그대로 출력하여 기울기 소실 문제를 줄인다."
},
{
  "question": "시그모이드 함수의 단점은?",
  "options": [
    "기울기가 일정하게 유지된다",
    "0을 출력하지 못한다",
    "입력이 작을수록 기울기가 0에 가까워진다",
    "음수 입력만 처리할 수 있다"
  ],
  "answer": 2,
  "explanation": "시그모이드는 입력이 너무 작거나 클 경우 미분값이 0에 가까워져 '기울기 소실' 문제가 발생한다."
},
{
  "question": "피마 인디언 당뇨병 데이터셋에서 높은 상관관계를 보인 항목은?",
  "options": [
    "나이와 당뇨 여부",
    "BMI와 공복 혈당 농도",
    "자녀 수와 당뇨 여부",
    "혈압과 혈소판 수치"
  ],
  "answer": 1,
  "explanation": "해당 데이터셋에서 당뇨 여부와 가장 높은 상관관계를 보인 항목은 BMI와 공복 혈당 농도(plasma)이다."
},
{
  "question": "피마 인디언 데이터셋을 사용할 때 필요한 전처리 과정으로 옳은 것은?",
  "options": [
    "텍스트 전처리",
    "이미지 정규화",
    "데이터 스케일링",
    "음성 분할"
  ],
  "answer": 2,
  "explanation": "피마 인디언 데이터는 수치 데이터이므로, 특성 간 스케일 차이를 줄이기 위한 스케일링이 중요하다."
},{
  "question": "결정 트리(Decision Tree)의 분류 기준으로 사용되는 개념은?",
  "options": [
    "정확도",
    "기울기",
    "불순도(impurity)",
    "거리 측정"
  ],
  "answer": 2,
  "explanation": "결정 트리는 데이터 분리를 위해 각 분기에서 불순도를 가장 많이 줄이는 조건을 선택한다."
},
{
  "question": "다음 중 결정 트리에 대한 설명으로 옳은 것은?",
  "options": [
    "모든 문제에 최적화되어 있다",
    "설명이 어려운 블랙박스 모델이다",
    "조건에 따라 데이터를 예/아니오로 반복 분기한다",
    "데이터의 거리 계산이 핵심이다"
  ],
  "answer": 2,
  "explanation": "결정 트리는 데이터에 대해 조건을 따라 예/아니오 식으로 나누며 분류한다."
},
{
  "question": "랜덤 포레스트(Random Forest)의 주요 특징은?",
  "options": [
    "하나의 깊은 트리를 사용한다",
    "복잡도는 낮지만 정확도가 떨어진다",
    "여러 결정 트리를 앙상블로 묶는다",
    "신경망 기반으로 작동한다"
  ],
  "answer": 2,
  "explanation": "랜덤 포레스트는 여러 개의 결정 트리를 학습시켜 결과를 투표 방식으로 종합하는 앙상블 기법이다."
},
{
  "question": "랜덤 포레스트에서 사용되는 앙상블 방식은?",
  "options": [
    "Boosting",
    "Stacking",
    "Bagging",
    "Pruning"
  ],
  "answer": 2,
  "explanation": "랜덤 포레스트는 훈련 데이터를 무작위로 샘플링하여 각 트리를 학습하는 Bagging 방식의 앙상블이다."
},
{
  "question": "에이다부스트(AdaBoost)의 핵심 원리는?",
  "options": [
    "가중치를 무작위로 초기화한다",
    "강한 모델 하나를 반복 사용한다",
    "약한 모델을 반복하여 성능을 보완한다",
    "모든 데이터를 제거한 뒤 학습한다"
  ],
  "answer": 2,
  "explanation": "AdaBoost는 잘못 분류된 샘플에 가중치를 두고 약한 모델을 반복적으로 학습시켜 성능을 개선한다."
},
{
  "question": "에이다부스트는 어떤 앙상블 방식에 해당하는가?",
  "options": [
    "Bagging",
    "Boosting",
    "Voting",
    "Stacking"
  ],
  "answer": 1,
  "explanation": "AdaBoost는 모델을 순차적으로 학습시키며 오차를 보정해 나가는 Boosting 방식이다."
},
{
  "question": "다음 중 앙상블 기법에 해당하지 않는 것은?",
  "options": [
    "Voting",
    "Boosting",
    "Clustering",
    "Bagging"
  ],
  "answer": 2,
  "explanation": "Clustering은 비지도 학습 기법이고, 나머지는 앙상블 기법에 해당한다."
},
{
  "question": "앙상블 기법 Voting의 특징은?",
  "options": [
    "여러 약한 모델을 순차적으로 연결한다",
    "모든 모델이 같은 유형이어야 한다",
    "서로 다른 모델들의 예측을 조합한다",
    "데이터의 차원을 줄여준다"
  ],
  "answer": 2,
  "explanation": "Voting은 다양한 모델을 병렬로 학습한 후, 다수결 또는 평균으로 최종 예측을 수행한다."
},
{
  "question": "아담(Adam) 옵티마이저가 다른 경사 하강법보다 나은 점은?",
  "options": [
    "가장 단순한 연산을 수행한다",
    "학습률을 자동으로 조정한다",
    "배치 사이즈가 필요 없다",
    "활성화 함수와 관계가 없다"
  ],
  "answer": 1,
  "explanation": "Adam 옵티마이저는 모멘텀과 학습률 조정 기능이 결합된 알고리즘으로, 자동으로 학습률을 최적화한다."
},
{
  "question": "다음 중 고급 경사 하강법에 해당하는 것은?",
  "options": [
    "평균 제곱 오차",
    "Adagrad",
    "XOR 모델",
    "MSE 최적화"
  ],
  "answer": 1,
  "explanation": "Adagrad는 학습률을 각 파라미터마다 다르게 조정하는 고급 경사 하강법 알고리즘이다."
},
  {
  "question": "EDA(탐색적 데이터 분석)의 주요 목적은?",
  "options": [
    "모델을 자동 튜닝하는 것",
    "데이터 속성의 통계 분석 및 시각화를 통해 인사이트를 얻는 것",
    "모델 성능을 평가하는 것",
    "정답 라벨을 추가하는 것"
  ],
  "answer": 1,
  "explanation": "EDA는 데이터를 직접 보고 시각화하며, 특성과 관계를 파악해 모델링에 앞서 인사이트를 얻는 과정이다."
},
{
  "question": "다음 중 EDA 단계에서 자주 사용하는 도구가 아닌 것은?",
  "options": [
    "히스토그램",
    "상관 행렬",
    "박스플롯",
    "아담 옵티마이저"
  ],
  "answer": 3,
  "explanation": "아담 옵티마이저는 모델 학습에 사용하는 도구이고, EDA와는 관련이 없다."
},
{
  "question": "에포크(epoch)의 의미는?",
  "options": [
    "모델의 정확도 수치",
    "전체 데이터셋을 1회 학습한 횟수",
    "데이터 전처리 횟수",
    "파라미터 개수"
  ],
  "answer": 1,
  "explanation": "에포크는 전체 훈련 데이터를 한 번 학습시키는 과정을 의미한다."
},
{
  "question": "배치 사이즈(batch size)가 너무 작을 경우 발생할 수 있는 문제는?",
  "options": [
    "메모리 부족",
    "학습 속도 저하",
    "오차 계산의 불안정성 증가",
    "학습률 감소"
  ],
  "answer": 2,
  "explanation": "배치 사이즈가 작으면 계산은 빠르지만 오차 계산의 진폭이 커져 불안정할 수 있다."
},
{
  "question": "입력층, 은닉층, 출력층으로 구성된 모델은?",
  "options": [
    "선형 회귀 모델",
    "로지스틱 회귀 모델",
    "다층 퍼셉트론",
    "결정 트리"
  ],
  "answer": 2,
  "explanation": "다층 퍼셉트론은 입력층, 은닉층, 출력층으로 구성된 심층 신경망 구조이다."
},
{
  "question": "Sequential 모델에 layer를 추가할 때 사용하는 메서드는?",
  "options": [
    "model.insert()",
    "model.define()",
    "model.compose()",
    "model.add()"
  ],
  "answer": 3,
  "explanation": "Keras의 Sequential 모델에 층을 추가할 때는 `model.add()`를 사용한다."
},
{
  "question": "Dense(1, activation='sigmoid')는 어떤 역할을 하는가?",
  "options": [
    "다층 입력층 생성",
    "출력층 구성 및 분류 확률 예측",
    "은닉층 구성",
    "학습률 조정"
  ],
  "answer": 1,
  "explanation": "Dense(1, activation='sigmoid')는 이진 분류용 출력층을 정의하는 코드이다."
},
{
  "question": "입력 데이터가 16개일 때 input_dim 설정은?",
  "options": [
    "16",
    "1",
    "0",
    "변동 가능"
  ],
  "answer": 0,
  "explanation": "입력 차원이 16이면 첫 Dense 층에서 input_dim=16으로 지정해야 한다."
},
{
  "question": "model.compile() 함수에서 설정할 수 없는 항목은?",
  "options": [
    "손실 함수",
    "옵티마이저",
    "정확도 지표",
    "입력 데이터"
  ],
  "answer": 3,
  "explanation": "model.compile()은 모델 구성 설정이고, 실제 입력 데이터는 model.fit()에서 입력된다."
},
{
  "question": "다중 분류 문제에서 사용하는 손실 함수는?",
  "options": [
    "binary_crossentropy",
    "mean_squared_error",
    "categorical_crossentropy",
    "hinge_loss"
  ],
  "answer": 2,
  "explanation": "다중 분류 문제에서는 `categorical_crossentropy` 손실 함수를 주로 사용한다."
},
{
  "question": "학습 정확도 외에 평가 지표로 쓰일 수 있는 것은?",
  "options": [
    "loss",
    "data rate",
    "RAM",
    "compile time"
  ],
  "answer": 0,
  "explanation": "모델 평가 시 정확도 외에도 손실 값(loss)을 지표로 활용한다."
},
{
  "question": "model.fit() 함수에서 설정할 수 있는 항목은?",
  "options": [
    "학습률",
    "입력/출력 데이터, epoch, batch_size",
    "레이어 구성",
    "손실 함수"
  ],
  "answer": 1,
  "explanation": "model.fit()은 실제 학습 실행 함수로, 학습 데이터, 에포크 수, 배치 크기 등을 설정한다."
},
{
  "question": "피마 인디언 당뇨병 예측에서 사용된 은닉층 수는?",
  "options": [
    "0개",
    "1개",
    "2개",
    "3개"
  ],
  "answer": 2,
  "explanation": "예제에서는 은닉층을 2개 설정해 모델을 구성하였다."
},
{
  "question": "은닉층의 노드 수를 12와 8로 설정한 이유는?",
  "options": [
    "데이터셋의 특성 수와 같다",
    "하이퍼파라미터 튜닝 결과",
    "설명과 실습 편의상 임의 설정",
    "시각화를 위해서"
  ],
  "answer": 2,
  "explanation": "교재에서는 실습의 이해를 돕기 위해 임의로 12와 8을 설정했다."
},
{
  "question": "데이터 시각화가 중요한 이유는?",
  "options": [
    "그래픽 공부를 위해",
    "모델을 만들기 위해",
    "데이터 분포와 특성 파악",
    "코드 줄이기"
  ],
  "answer": 2,
  "explanation": "시각화는 데이터의 분포, 이상치, 상관관계를 파악하는 데 매우 유용하다."
},
{
  "question": "다음 중 pandas로 시각화를 하기 위해 함께 사용하는 라이브러리는?",
  "options": [
    "numpy",
    "matplotlib",
    "keras",
    "sklearn"
  ],
  "answer": 1,
  "explanation": "pandas의 시각화는 matplotlib 또는 seaborn을 함께 사용한다."
},
{
  "question": "pandas의 iloc[] 함수의 주된 목적은?",
  "options": [
    "행과 열 이름으로 접근",
    "인덱스 기반 행/열 추출",
    "데이터 요약",
    "차트 출력"
  ],
  "answer": 1,
  "explanation": "`iloc[]`는 위치 기반으로 행과 열을 추출할 수 있는 pandas의 핵심 기능이다."
},
{
  "question": "히스토그램을 그릴 수 있는 matplotlib 함수는?",
  "options": [
    "plot()",
    "scatter()",
    "hist()",
    "bar()"
  ],
  "answer": 2,
  "explanation": "hist() 함수는 수치형 데이터의 분포를 확인하는 히스토그램을 그릴 수 있다."
},
{
  "question": "plasma 수치가 높을수록 어떤 경향이 있었나?",
  "options": [
    "정상 확률 증가",
    "데이터 누락 증가",
    "당뇨 예측 확률 증가",
    "데이터 오류 증가"
  ],
  "answer": 2,
  "explanation": "plasma 수치(공복 혈당 농도)가 높을수록 당뇨 확률이 높은 경향이 있었다."
},
{
  "question": "BMI가 높을 경우 나타난 경향은?",
  "options": [
    "정상인 비율이 높아짐",
    "당뇨 발병률 증가",
    "데이터 일관성 감소",
    "정확도 증가"
  ],
  "answer": 1,
  "explanation": "BMI가 높을수록 당뇨 발병률이 높아지는 경향이 있는 것으로 분석되었다."
},
{
  "question": "데이터 전처리 시 결측값 처리 방법으로 적절한 것은?",
  "options": [
    "결측값 제거만 가능",
    "평균이나 중앙값으로 대체 가능",
    "결측값은 무조건 에러",
    "0으로 고정"
  ],
  "answer": 1,
  "explanation": "결측값은 평균, 중앙값 등으로 대체하거나 제거할 수 있다."
},
{
  "question": "이상치 제거의 목적은?",
  "options": [
    "데이터를 더 무작위로 만들기 위해",
    "데이터 양을 줄이기 위해",
    "모델의 안정성과 정확도 향상",
    "훈련 속도 저하"
  ],
  "answer": 2,
  "explanation": "이상치는 모델에 왜곡된 영향을 줄 수 있어 제거하면 정확도가 향상될 수 있다."
},
{
  "question": "데이터의 상관관계를 시각화하기 위한 함수는?",
  "options": [
    "corr() + heatmap()",
    "scatter()",
    "boxplot()",
    "dropna()"
  ],
  "answer": 0,
  "explanation": "`corr()`로 상관관계를 구하고, `heatmap()`으로 시각화할 수 있다."
},
{
  "question": "딥러닝 프로젝트에서 가장 중요한 초기 단계는?",
  "options": [
    "모델 설계",
    "데이터 정제와 탐색",
    "손실 함수 설정",
    "활성화 함수 고르기"
  ],
  "answer": 1,
  "explanation": "좋은 데이터를 확보하고 잘 정제하는 것이 프로젝트 성공의 핵심이다."
}




]
